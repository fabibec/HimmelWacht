\chapter{Objekttracking}
\section{Ziel des Objekttrackings (Jürgens, Specht)}
Eine optionale Anforderung die in diesem Projekt am Ende noch aktiv verfolgt und umgesetzt wurde, war die Implementierung eines Objekttrackings. So sollte es möglich sein, die Koordinaten der Bounding Box zur Steuerung des Geschützarms zu verwenden. Das Ziel war also, den Geschützarm immer so auszurichten, dass die Bounding Box des Objekts immer im Zentrum des Kamerabildes ist. 

\section{Einrichtung des Kommunikationskanals (Jürgens)}
Um tatsächlich Steuersignale an den Roboter zu senden, muss zunächst entschieden werden, wie dies geschehen soll. Dabei gab es zwei Ansätze die in Betracht gezogen wurden: 
\begin{itemize}
    \item Kommunikation über WebSockets
    \item Kommunikation über MQTT
\end{itemize}
Nach Absprachen mit dem Team wurde entschieden, dass die Kommunikation über MQTT erfolgen soll. Dies hat den Vorteil, dass mittels eines MQTT-Brokers eine zentrale Stelle geschaffen wird, an der alle Nachrichten gesammelt werden können. Dies ermöglicht neben dem grundlegend einfachen Austausch von Nachrichten auch eine gute Möglichkeit um das Projekt zu erweitern. So könnten weitere Sensorwerte oder auch die Stellung der Motoren über den MQTT-Broker ausgetauscht werden und optional für weitere Aktionen verwendet werden. \\

Es wurde sich für eine Lösung mit dem Open-Source MQTT-Broker \texttt{Mosquitto} geeinigt. Dieser MQTT-Broker stellt eine leichtgewichtige Lösung bereit, welche nach dem Publish-Subscribe-Prinzip arbeitet \cite{Mosquitto}. So kann jeder Subscriber (Abonnent) ein oder mehrere Topics (Themen) abonnieren und erhält über diese Subscription dann die entsprechenden Nachrichten. Dieser Ansatz soll den Nachrichtenverkehr für den Microcontroller minimieren, da hier zuvor bereits selektiert wird, welche Topics abonniert werden. 
\\ 
Die Mosquitto-Instanz wird auf dem Laborrechner installiert und ausgeführt. Die Konfiguration erfolgt über eine zentrale Konfigurationsdatei. Trotz korrekter Konfiguration konnte zunächst keine Verbindung zwischen dem MQTT-Broker und dem ESP32 hergestellt werden. Dieser Umstand wurde durch Ergänzung von Firewall-Regeln auf dem Laborrechner behoben. Es wurde auf dem Windows-Rechner explizit eine eingehende und ausgehende Regel für die Applikation Mosquitto erstellt. So konnte erfolgreich eine Verbindung zwischen dem ESP32 und dem MQTT-Broker hergestellt werden.

\section{Implementierung des Objekttrackings (Jürgens, Specht)} \label{sec:objekttracking}
Mit bestehender und funktionierender MQTT-Verbindung konnte nun das Objekttracking implementiert werden. Dabei musste besonders auf die Art und Weise geachtet werden, wie die Motorsteuerung implementiert wurde. Die Motoren werden mit Statusnachrichten versorgt, welche die absolute Position der Motoren angeben. So würde das Senden mehrere Nachrichten mit dem selben Inhalt zu einer einzigen Bewegung führen. Somit sind die Nachrichten idempotent und können mehrfach gesendet werden, ohne dass sich die Position der Motoren ändert.
Wichtig war außerdem, dass die Berechnung der Drehwinkel auf dem Laborrechner erfolgt. Hiermit soll der ESP32 entlastet werden, da dieser nur als Abonnent des MQTT-Topics fungiert und die Motoren steuert. 
\\
Mit diesem Wissen wurde zunächst der Ansatz eines Mappings verfolgt. Dabei wurde der Geschützarm in die Null-Stellung gebracht. Durch Trial-and-Error wurden dabei die maximal benötigten Drehwinkel der Motoren, die benötigt werden um die Kamera an den Bildrand zu bewegen, ermittelt. Diese Werte wurden dann in ein Mapping überführt. So sollte sich das errechnete Zentrum der Bounding Box in einen benötigten Drehwinkel übersetzen lassen.\\
Dieses Vorgehen hat sich jedoch als nicht praktikabel herausgestellt. Es wurde beispielsweise für das Erreichen des rechten Bildrandes eine andere Motorstellung benötigt als für das Erreichen des linken Bildrandes. So wurde beispielsweise für das Erreichen des rechten Bildrandes der horizontale Winkel -15 benötigt, für das Erreichen des linken Bildrandes aber +18. Aufgrund dieser Abweichungen und einem inkosistenten Auflösung der Motoren wurde der Ansatz verworfen und nicht weiter verfolgt.
\\
Der zweite Ansatz wurde gemeinsam mit Michael Specht erarbeitet und verfolgt die Idee, die Kameramerkmale direkt mit in die Berechnung des Drehwinkels einzubeziehen. Dieser Ansatz erwies sich als deutlich erfolgreicher. Die damit einhergehende Komplexität war jedoch höher als zuvor. Das Projekt war zu diesem Zeitpunkt bereits sehr weit fortgeschritten, weshalb sich das Ziel gesetzt wurde, einen einfachen Entwurf zu erstellen, der die grundlegende Funktionsweise des Objekttrackings demonstriert und die Erweiterbarkeit des Projekts zeigt. \newline

Im ersten Schritt war es wichtig, die Kameramerkmale zu ermitteln. Die Recherche ergab, dass die Kamera ein diagonales Sichtfeld von $75^\circ$ und eine Auflösung von 1280x1080 Pixeln hat. Weitere Merkmale, wie beispielsweise der vertikale und horizontale Sichtwinkel (field of view, FOV) konnten für das Raspberry Camera Module 3 nicht gefunden werden. Mittels Claude.ai wurde folgender Ansatz entworfen, um die Parameter programmatisch zu ermitteln: \newline

Gegeben ist ein diagonales Sichtfeld von $75^\circ$ sowie eine Bildauflösung von $1280 \times 1080$ Pixeln. Daraus ergibt sich ein Seitenverhältnis von
\[
r = \frac{1280}{1080} \approx 1{,}185.
\]
Der diagonale FOV wird zunächst in Bogenmaß umgerechnet:
\[
\varphi_d = \mathrm{rad}(75^\circ).
\]
Die horizontalen und vertikalen FOVs berechnen sich über trigonometrische Umformungen für rechteckige Sensoren zu:
\[
\varphi_h = 2 \cdot \tan^{-1} \left( \frac{r \cdot \tan(\varphi_d/2)}{\sqrt{1 + r^2}} \right), \quad
\varphi_v = 2 \cdot \tan^{-1} \left( \frac{\tan(\varphi_d/2)}{\sqrt{1 + r^2}} \right).
\]
Einsetzen der Werte ergibt:
\[
\varphi_h \approx 60{,}8^\circ, \quad \varphi_v \approx 52{,}7^\circ.
\]

Diese Werten konnten für die weitere Berechnung der Drehwinkel verwendet werden. Auch dieser Teil wurde mit Hilfe von Claude.ai erarbeitet. Dabei war die Grundidee, eine Klasse namens \textit{ServoTracker} zu erstellen, die die Kameramerkmale und die absoluten Winkelpositionen der Motoren enthält. Die Funktionalität der Klasse ist im Wesentlichen in zwei Funktionen unterteilt:

\begin{enumerate}
    \item \textit{calculate\_camera\_relative\_angles}: Diese Funktion berechnet die relativen Drehwinkel in horizontaler und vertikaler Richtung zwischen dem Zentrum des Kamerabildes und dem erkannten Punkt bzw. dem Mittelpunkt der Bounding Box. Dabei wird der horizontale und vertikale FOV der Kamera auf die Anzahl der Bildpunkte (Pixel) umgerechnet, um so einen Winkel pro Pixel zu erhalten. Die Winkelabweichung ergibt sich anschließend durch die Differenz zwischen dem Zielpunkt und dem Bildzentrum.
    
    \item \textit{update\_servo\_position}: Diese Funktion nimmt die zuvor berechneten relativen Winkel und überträgt sie auf die aktuellen absoluten Positionen der Servomotoren. Wichtig ist dabei, dass die zuvor berechneten relativen Winkel auf den derzeitigen Absolutwinkel addiert werden, da diese auch negativ sein können. Darüber hinaus werden Grenzen für minimale und maximale Positionen berücksichtigt, um mechanische Einschränkungen zu vermeiden. Anschließend werden die neuen Winkel gespeichert und zurückgegeben.
\end{enumerate}

Zusätzlich wurden zwei Hilfsfunktionen implementiert: \textit{get\_current\_position} gibt die aktuell gespeicherten absoluten Positionen der Servos zurück, während \textit{reset\_to\_zero} die Motoren auf eine definierte Ausgangsposition zurücksetzt bzw. die Kamera geradeaus ausrichtet. \newline

Die Klasse ermöglicht somit eine einfache und direkte Umsetzung einer objektzentrierten Verfolgung durch Umrechnung von Bildkoordinaten in mechanische Steuerbefehle. \newline

Nun war es wichtig, Randbedingungen festzulegen, sodass beispielsweise genügend Zeit bleibt, um die Motoren zu bewegen und ein neues Bild zu erhalten. Bei der Definition unterstützte auch der Kollege Fabian Becker. Diese Randbedingungen waren für das Objekttracking relevant:

\begin{itemize}
    \item \textit{Reset nach 5 Sekunden}: Die Kamera liefert 30 Frames pro Sekunde, was bedeutet, dass 150 Frames in 5 Sekunden verarbeitet werden. Diese Zeit wird mit einem einfachen Counter überwacht. Über den Modulooperator wird geprüft, ob der Counter den Wert 150 erreicht hat. In diesem Fall wird die Kamera auf die Null-Position zurückgesetzt und der Counter auf 0 gesetzt. Außerdem werden die Motoren auf die Null-Position zurückgesetzt. Dies ist wichtig, da der Zustand der Motoren nur über die Klasse \textit{ServoTracker} verwaltet wird und nicht über die MQTT-Kommunikation. Damit ist gemeint, dass keine Motorwerte über MQTT empfangen werden.
    
    \item \textit{Minimale Bewegung ignorieren}: Um zu verhindern, dass kleine Bewegungen der Kamera bereits zu eine Neupositionierung des Geschützarms bzw. der Plattform führen, wurde eine Deadzone von $7^\circ$ definiert. Dies bedeutet, dass die neue relative Abweichung von mindestens einer Achse (vertikal oder horizontal) größer-gleich $7^\circ$ sein muss. Anderenfalls wird die Ausrichtung nicht verändert.
    
    \item \textit{Bilder für Berechnung begrenzen}: Aufgrund von Latenzen zwischen der Interferenz, der Übertragung der Daten und der Verarbeitung der Bilder, wurde sich darauf festgelegt, nur jedes 7. Bild für die Berechnung der neuen Position zu verwenden. Dies wurde durch Testing im Labor ermittelt und hat sich als praktikabel erwiesen.
\end{itemize}

Abschließend wurden sowohl die Funktionen als auch die Hilfsfunktionen der Klasse in Kombination mit den Randbedingungen und der MQTT-Kommunikation in die Funktion \textit{run\_track} integriert. Diese Funktion wird bei einem vorhandenem Track, also Stream, aufgerufen. Dies geschieht solange, bis ein Peer die Verbindung abbricht. Dabei ist zu beachten, dass die MQTT-Nachrichten auch im manuellen Modus immer gesendet werden, da somit die Notwendigkeit entfällt den Betriebsmodus des Geschützes auch auf dem Laborrechner mitzuverfolgen. Der ESP32 entscheidet also selbstständig, ob er die Nachrichten verarbeitet oder ignoriert. 